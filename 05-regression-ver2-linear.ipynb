{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import folium\n",
    "import os\n",
    "import geohash\n",
    "from folium.plugins import HeatMap\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error, mean_squared_log_error\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(RESULTS_DIR, \"10_million_with_elevation_geohashes_timestamps.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>value</th>\n",
       "      <th>geohash</th>\n",
       "      <th>geohash5</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>xn7tncn498k2</td>\n",
       "      <td>xn7tn</td>\n",
       "      <td>1.540076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>xnezj2x7rnh7</td>\n",
       "      <td>xnezj</td>\n",
       "      <td>1.540076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>xneysek46d7w</td>\n",
       "      <td>xneys</td>\n",
       "      <td>1.540076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>u336qgr9tvzw</td>\n",
       "      <td>u336q</td>\n",
       "      <td>1.540076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>xneyyr50hk99</td>\n",
       "      <td>xneyy</td>\n",
       "      <td>1.540076e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  value       geohash geohash5     timestamp\n",
       "0           0   23.0  xn7tncn498k2    xn7tn  1.540076e+09\n",
       "1           1   19.0  xnezj2x7rnh7    xnezj  1.540076e+09\n",
       "2           2   15.0  xneysek46d7w    xneys  1.540076e+09\n",
       "3           3   16.0  u336qgr9tvzw    u336q  1.540076e+09\n",
       "4           4   18.0  xneyyr50hk99    xneyy  1.540076e+09"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310.4768877404536, 34.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_geohashes_prec_5 = df.geohash5.value_counts()\n",
    "points_geohashes_prec_5.mean(), points_geohashes_prec_5.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11920"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geohashes_for_regression = list(points_geohashes_prec_5.where(lambda count: count >= 50).dropna().index)\n",
    "len(geohashes_for_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11920"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupped_df = df[df.geohash5.isin(geohashes_for_regression)][[\"value\", \"geohash5\", \"timestamp\"]].groupby(\"geohash5\")\n",
    "len(groupped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_linear_regresion_model(data):\n",
    "    data = data.sort_values(by=['timestamp'])\n",
    "    new_data = pd.DataFrame(data=[[]])\n",
    "    size = data.shape[0]\n",
    "    new_data['count'] = size\n",
    "    \n",
    "    if size <= 1:\n",
    "        new_data['regresion'] = None\n",
    "        new_data['reg_mean_squared_error'] = None\n",
    "        new_data['reg_r2_score_error'] = None\n",
    "        new_data['reg_median_absolute_error'] = None\n",
    "#         new_data['reg_mean_squared_log_error'] = None\n",
    "        return new_data\n",
    "    \n",
    "    train_size = int(0.8 * size)\n",
    "    test_size = size - train_size\n",
    "    \n",
    "    X_train = np.array(data.timestamp[:train_size]).reshape(-1, 1)\n",
    "    X_test = np.array(data.timestamp[train_size:]).reshape(-1, 1)\n",
    "    \n",
    "    Y_train = np.array(data.value[:train_size]).reshape(-1, 1)\n",
    "    Y_test = np.array(data.value[train_size:]).reshape(-1, 1)\n",
    "    \n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    regr.fit(X_train, Y_train)\n",
    "    new_data['regresion'] = regr\n",
    "    \n",
    "    Y_pred = regr.predict(X_test)\n",
    "    # mean_squared_error, r2_score, median_absolute_error, mean_squared_log_error\n",
    "    new_data['reg_mean_squared_error'] = mean_squared_error(Y_test, Y_pred)\n",
    "    new_data['reg_r2_score_error'] = r2_score(Y_test, Y_pred)\n",
    "    new_data['reg_median_absolute_error'] = median_absolute_error(Y_test, Y_pred)\n",
    "#     new_data['reg_mean_squared_log_error'] = mean_squared_log_error(Y_test, Y_pred)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after_training = groupped_df.apply(prepare_linear_regresion_model).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohash5</th>\n",
       "      <th>level_1</th>\n",
       "      <th>count</th>\n",
       "      <th>regresion</th>\n",
       "      <th>reg_mean_squared_error</th>\n",
       "      <th>reg_r2_score_error</th>\n",
       "      <th>reg_median_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6mc5m</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>15.734465</td>\n",
       "      <td>0.093991</td>\n",
       "      <td>3.940649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6mc5n</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>184.964721</td>\n",
       "      <td>-7.283024</td>\n",
       "      <td>13.549167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6mc5p</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>133.037319</td>\n",
       "      <td>-9.413464</td>\n",
       "      <td>12.284661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6mc5t</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>18.379484</td>\n",
       "      <td>-0.759223</td>\n",
       "      <td>3.521412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6msem</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
       "      <td>25.458074</td>\n",
       "      <td>-0.055333</td>\n",
       "      <td>3.927389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geohash5  level_1  count                                          regresion  \\\n",
       "0    6mc5m        0    167  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "1    6mc5n        0    162  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "2    6mc5p        0     70  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "3    6mc5t        0     96  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "4    6msem        0    119  LinearRegression(copy_X=True, fit_intercept=Tr...   \n",
       "\n",
       "   reg_mean_squared_error  reg_r2_score_error  reg_median_absolute_error  \n",
       "0               15.734465            0.093991                   3.940649  \n",
       "1              184.964721           -7.283024                  13.549167  \n",
       "2              133.037319           -9.413464                  12.284661  \n",
       "3               18.379484           -0.759223                   3.521412  \n",
       "4               25.458074           -0.055333                   3.927389  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after_training_mean_squared = df_after_training[df_after_training.reg_mean_squared_error <= 100]\n",
    "df_after_training_reg_r2_score = df_after_training[df_after_training.reg_r2_score_error <= 100][df_after_training.reg_r2_score_error >= -10]\n",
    "df_after_training_median_absolute = df_after_training[df_after_training.reg_median_absolute_error <= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(geo):\n",
    "    bbox = geohash.bbox(geo)\n",
    "    return [[bbox[\"w\"], bbox[\"n\"]], [bbox[\"e\"], bbox[\"n\"]], [bbox[\"e\"], bbox[\"s\"]], [bbox[\"w\"], bbox[\"s\"]]]\n",
    "\n",
    "def get_geo_data(ghash_df):\n",
    "    features = []\n",
    "\n",
    "    for geo, *_ in ghash_df.values:\n",
    "        features.append({\"type\": \"Feature\", \"id\": geo, \n",
    "                         \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [get_coordinates(geo)]}})\n",
    "\n",
    "    return {\"type\": \"FeatureCollection\", \"features\": features}\n",
    "\n",
    "def visualize_with_folium(df, error):\n",
    "    m = folium.Map(location=[37.760806, 140.474722], zoom_start=10)\n",
    "\n",
    "    m.choropleth(\n",
    "        geo_data=get_geo_data(df),\n",
    "        name='choropleth',\n",
    "        data=df,\n",
    "        columns=['geohash5', error],\n",
    "        key_on='feature.id',\n",
    "        fill_color='YlOrRd',\n",
    "        fill_opacity=0.7,\n",
    "        line_opacity=0.2,\n",
    "        legend_name='error'\n",
    "    )\n",
    "    folium.LayerControl().add_to(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_mean_squared = visualize_with_folium(df_after_training_mean_squared, 'reg_mean_squared_error')\n",
    "m_reg_r2_score = visualize_with_folium(df_after_training_reg_r2_score, 'reg_r2_score_error')\n",
    "m_median_absolute = visualize_with_folium(df_after_training_median_absolute, 'reg_median_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_mean_squared.save(os.path.join(RESULTS_DIR, \"linear_regression_mean_squared_errors.html\"))\n",
    "m_reg_r2_score.save(os.path.join(RESULTS_DIR, \"linear_regression_reg_r2_score_errors.html\"))\n",
    "m_median_absolute.save(os.path.join(RESULTS_DIR, \"linear_regression_median_absolute_errors.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
